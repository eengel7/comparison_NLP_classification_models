{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classification import (\n",
    "    MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    ")\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from src.training import train_model\n",
    "from src.evaluation import eval_model\n",
    "from src.preprocessing.get_preprocessed_data import get_preprocessed_data\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from src.utils import prepare_df\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Experiment config:----------------------\n",
    "model_type = 'bert'\n",
    "model_name = \"bert-base-uncased\" # 'bert-base-uncased' ,\"roberta-base\", \"outputs/checkpoint-120-epoch-1\",\n",
    "\n",
    "model_args = MultiLabelClassificationArgs(\n",
    "                                          wandb_project ='multi_label_transformer', \n",
    "                                          wandb_kwargs = {\"name\": model_name},\n",
    "                                          learning_rate = 5e-5,\n",
    "                                          num_train_epochs=15,\n",
    "                                          train_batch_size = 4,\n",
    "                                          eval_batch_size = 4,\n",
    "                                          ) \n",
    "model = MultiLabelClassificationModel(\n",
    "    model_type,\n",
    "    model_name,\n",
    "    num_labels=305,\n",
    "    args=model_args,\n",
    ")\n",
    "# -----------------------------------\n",
    "# Prepare data\n",
    "X_train, X_test, X_val, Y_train, Y_test, Y_val = get_preprocessed_data(model_type, overwrite_data= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_df(X_train, Y_train)\n",
    "test_df = prepare_df(X_test, Y_test)\n",
    "val_df = prepare_df(X_val, Y_val)\n",
    "print('Data is loaded.')\n",
    "\n",
    "train_model(model, train_df, eval_df = val_df)\n",
    "\n",
    "# # Evaluate the model\n",
    "# result, model_outputs, wrong_predictions = eval_model(model,\n",
    "#     test\n",
    "# )\n",
    "\n",
    "#print(result, model_outputs, wrong_predictions)\n",
    "# # Make predictions with the model\n",
    "# predictions, raw_outputs = model.predict([\"Sam\"])\n",
    "\n",
    "# print(predictions,raw_outputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9883284e4809f9dc439720b7be050568a57fcaf846432ff7264a79bbda205b99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
